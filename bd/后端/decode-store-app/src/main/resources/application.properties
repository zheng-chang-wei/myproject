spring.profiles.active=local

kafka.producer.retries=10
kafka.producer.batch.size=4096
kafka.producer.linger=1
#5M
kafka.producer.buffer.memory=5242880
kafka.producer.acks=1
kafka.producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer

kafka.consumer.enable.auto.commit=true
kafka.consumer.session.timeout=6000
kafka.consumer.auto.commit.interval=100
kafka.consumer.auto.offset.reset=latest
kafka.consumer.topic=train-ground
kafka.consumer.group.register=decode-store
kafka.consumer.group.prefix=store-
kafka.consumer.concurrency=3
kafka.consumer.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.value.deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer

#报文主题前缀
kafka.original.topic.prefix=decode-message-

#解析报文父目录
store.file.container=p
#解析报文文件扩展名
store.file.extension=.par

#缓存buffer大小
store.file.buffer.capacity=2097152
#写文件频率，单位秒，默认为5
store.file.write.period=5
#文件切换时间间隔，单位小时，默认为1小时
store.file.interval=1
#切换文件定时器表达式
store.file.create.period=0 0 0/1 * * ? 

#文件上传定时器表达式
store.file.upload.period=0 0 0/6 * * ? 

#hdfs平台
#大数据平台数据存储根目录
store.hdfs.root=/data
#hdfs运行的linux系统的用户名
store.hdfs.username=hdfs

data.record.topic=big-data-record